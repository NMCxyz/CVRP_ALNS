{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALNS algorithms for Capacitated Vehicle Routing problem\n",
    "\n",
    "### Reference\n",
    "---\n",
    "  - Lutz, Roman. \"*Adaptive large neighborhood search.*\" (2015).\n",
    "  - Bent, Russell, and Pascal Van Hentenryck. \"*A two-stage hybrid algorithm for pickup and delivery vehicle routing problems with time windows.*\" Computers & Operations Research 33.4 (2006): 875-893.\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ipywidgets\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "import xlsxwriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tsplib95 import distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVRP\n",
    "## Parameters Setup\n",
    "- *rand_d_max*: max degree of random destruction\n",
    "- *rand_d_min*: min degree of random destruction\n",
    "- *worst_d_max*: max degree of worst destruction\n",
    "- *worst_d_min*: min degree of worst destruction\n",
    "- *regret_n*:  n next cheapest insertions\n",
    "- *r1*: reward if the new solution is the best one found so far.\n",
    "- *r2*: reward if the new solution improves the current solution.\n",
    "- *r3*: reward if the new solution does not improve the current solution, but is accepted.\n",
    "- *rho* $\\rho$: reaction factor of weight adjustments\n",
    "- *phi* $\\phi$ : the reduction factor of threshold acceptance\n",
    "- *epochs*: Iterations\n",
    "- *pu*: the number of iterations that are executed before an adjustment a.k.a update period\n",
    "- *vehicle_cap*: Vehicle capacity\n",
    "- *tol*: tolerance for threshold acceptance\n",
    "- *opt_type*: Optimization \n",
    "    - type:0:Minimize the number of vehicles,\n",
    "    - type:1:Minimize travel distance\n",
    "- *varphi* $\\varphi$ : \n",
    "- *psi* $\\psi$ : \n",
    "<br>\n",
    "\n",
    "#### Further Extensions and Adjustments\n",
    "- Noising\n",
    "- Penalties for time-intensive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sol():\n",
    "    def __init__(self):\n",
    "        self.nodes_sequence=None\n",
    "        self.obj=None\n",
    "        self.routes=None\n",
    "\n",
    "class Node():\n",
    "    def __init__(self):\n",
    "        self.id=0\n",
    "        self.sequence_no=0\n",
    "        self.coord = {}\n",
    "        self.request=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "We need to set a model including all variables needed in the problem\n",
    "\n",
    "### Degree of destruction parameters\n",
    "![image info](./datatest/Degreeofdestruction.png \"Degree of destruction\")\n",
    "<br>\n",
    "The degree shouldn't be too large, otherwise the runtime of repair heuristics will increase dramatically.\n",
    "<br>\n",
    "\n",
    "### Acceptance method\n",
    "The method used in this test is Threshold Acceptance (TA): <br>\n",
    "The solution $s_0$ is accepted, if $c(s') - c(s) < T$ with a\n",
    "threshold $T$. The threshold is decreased in every iteration by a factor $\\phi$. <br>\n",
    "#### Acceptance parameters\n",
    "![image info](./datatest/accept.png) <br>\n",
    "T is set so that the initially worst acceptable solution\n",
    "has tol percent higher costs than the initial solution. \n",
    "$$T = tol Â· c(s_{init}).$$\n",
    "Due to the book: the best solutions of the tuning were\n",
    "found with Threshold Acceptance (TA), so for all further tunings, TA was used. The\n",
    "best values for the reduction factor $\\phi$ were between 0.9996 and 0.9998, so we\n",
    "choose 0.9997. <br>The increase factor is not used by Threshold Acceptance, so it\n",
    "did not occur in the results. The tolerance *tol* varied from 0.0075 to 0.0142 (From 0 to 0.3 as shown in table). A\n",
    "value around one percent seems appropriate, so *tol* was fixed to 0.01 (We can set different values for testing).<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set value\n",
    "rand_d_max=0.4\n",
    "rand_d_min=0.1\n",
    "worst_d_min=5\n",
    "worst_d_max=20\n",
    "related_d_min = 0.1\n",
    "related_d_max = 0.4\n",
    "regret_n=5\n",
    "r1=65\n",
    "r2=45\n",
    "r3=25\n",
    "rho=0.35\n",
    "phi=0.9997\n",
    "epochs=10\n",
    "pu=5\n",
    "vehicle_cap=80\n",
    "opt_type=1\n",
    "tol = 0.2\n",
    "varphi = 2\n",
    "psi = 1\n",
    "\n",
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.best_sol=None\n",
    "        self.node_list=[]\n",
    "        self.node_seq_no_list=[]\n",
    "        self.depot=None\n",
    "        self.number_of_nodes=0\n",
    "        self.opt_type=opt_type\n",
    "        self.vehicle_cap = vehicle_cap\n",
    "        self.distance = {}\n",
    "        self.rand_d_max=rand_d_max\n",
    "        self.rand_d_min=rand_d_min\n",
    "        self.worst_d_max=worst_d_max\n",
    "        self.worst_d_min=worst_d_min\n",
    "        self.related_d_min=related_d_min\n",
    "        self.related_d_max=related_d_max\n",
    "        self.regret_n=regret_n\n",
    "        self.r1=r1\n",
    "        self.r2=r2\n",
    "        self.r3=r3\n",
    "        self.rho=rho\n",
    "        self.varphi=varphi\n",
    "        self.psi=psi\n",
    "        self.d_weight=np.ones(2)*10\n",
    "        self.d_select=np.zeros(2)\n",
    "        self.d_score=np.zeros(2)\n",
    "        self.d_history_select=np.zeros(2)\n",
    "        self.d_history_score=np.zeros(2)\n",
    "        self.r_weight=np.ones(3)*10\n",
    "        self.r_select=np.zeros(3)\n",
    "        self.r_score=np.zeros(3)\n",
    "        self.r_history_select = np.zeros(3)\n",
    "        self.r_history_score = np.zeros(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataFile(filepath, model):\n",
    "    # sep = separator in data file\n",
    "    node_sequence_no = -1\n",
    "    df = pd.read_csv(filepath, sep = \"\\t\")\n",
    "    for i in range(0,df.shape[0]):\n",
    "        node = Node()\n",
    "        node.id=node_sequence_no\n",
    "        node.sequence_no=node_sequence_no\n",
    "        node.coord = (df['x_coord'][i] , df['y_coord'][i])\n",
    "        node.request=df['request'][i]\n",
    "        if df['request'][i] == 0:\n",
    "            model.depot=node\n",
    "        else:\n",
    "            model.node_list.append(node)\n",
    "            model.node_seq_no_list.append(node_sequence_no)\n",
    "\n",
    "        node.id=df['id'][i]\n",
    "        node_sequence_no=node_sequence_no + 1\n",
    "    model.number_of_nodes=len(model.node_list)\n",
    "\n",
    "model = Model()\n",
    "readDataFile('../CVRP_ALNS/datatest/ALNS_CVRP.txt', model)\n",
    "# print(model.depot.coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_between_points(p1, p2): \n",
    "    return math.sqrt((p1[0]-p2[0])**2+(p1[1]-p2[1])**2) \n",
    "\n",
    "# Create a distance matrix between points\n",
    "def initParam(model):\n",
    "    for i in range(model.number_of_nodes):\n",
    "        for j in range(i+1,model.number_of_nodes):\n",
    "            dis = dis_between_points(model.node_list[i].coord,model.node_list[j].coord)\n",
    "            # print(dis)\n",
    "            model.distance[i,j]=dis\n",
    "            model.distance[j,i]=dis\n",
    "            \n",
    "\n",
    "initParam(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Solution Construction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 8, 11, 7, 48, 13, 1, 91, 94, 54, 16, 63, 52, 41, 80, 2, 47, 87, 78, 66, 19, 6, 24, 10, 59, 30, 22, 29, 83, 37, 93, 81, 43, 99, 86, 28, 34, 88, 44, 14, 84, 70, 4, 20, 15, 21, 31, 76, 57, 67, 73, 50, 69, 25, 98, 46, 96, 0, 72, 35, 58, 92, 3, 95, 56, 90, 26, 40, 55, 89, 75, 71, 60, 42, 9, 82, 39, 18, 77, 68, 32, 79, 12, 85, 36, 17, 64, 27, 74, 45, 61, 38, 51, 62, 65, 33, 5, 53, 97, 49]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def genInitialSol(node_sequence):\n",
    "    node_sequence = copy.deepcopy(node_sequence)\n",
    "    random.seed(0) # To make sure \n",
    "    random.shuffle(node_sequence) # Reorder node_sequence (The index of nodes)\n",
    "    return node_sequence\n",
    "\n",
    "# Minimizing the number of vehicles since we don't have any information about them\n",
    "def splitRoutes(nodes_sequence,model):\n",
    "    num_vehicle = 0\n",
    "    vehicle_routes = []\n",
    "    route = []\n",
    "    remained_cap = model.vehicle_cap\n",
    "\n",
    "    for node_no in nodes_sequence:\n",
    "        if remained_cap - model.node_list[node_no].request >= 0:\n",
    "            route.append(node_no)\n",
    "            remained_cap = remained_cap - model.node_list[node_no].request\n",
    "        else:\n",
    "            vehicle_routes.append(route)\n",
    "            route = [node_no]\n",
    "            num_vehicle = num_vehicle + 1\n",
    "            remained_cap =model.vehicle_cap - model.node_list[node_no].request\n",
    "    vehicle_routes.append(route)\n",
    "    \n",
    "    return num_vehicle,vehicle_routes\n",
    "\n",
    "print(genInitialSol(model.node_seq_no_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calDistance(route,model):\n",
    "    distance=0\n",
    "    depot=model.depot\n",
    "    for i in range(len(route)-1):\n",
    "        distance+=model.distance[route[i],route[i+1]]\n",
    "    first_node=model.node_list[route[0]]\n",
    "    last_node=model.node_list[route[-1]]\n",
    "    distance+=dis_between_points(depot.coord, first_node.coord)\n",
    "    distance+=dis_between_points(depot.coord, last_node.coord)\n",
    "    return distance\n",
    "    \n",
    "def calObj(nodes_sequence,model):\n",
    "    num_vehicle, vehicle_routes = splitRoutes(nodes_sequence, model)\n",
    "    if model.opt_type==0:\n",
    "        return num_vehicle,vehicle_routes\n",
    "    else:\n",
    "        distance=0\n",
    "        for route in vehicle_routes:\n",
    "            distance+=calDistance(route,model)\n",
    "        return distance,vehicle_routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Destroy Operators\n",
    "### Random Removal\n",
    "The idea in Random Removal is pretty simple. It creates diversification in heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRandomDestory(model):\n",
    "    #Select a random degree of destruction from [dmin,dmax] in every iteration.\n",
    "    d=random.uniform(model.rand_d_min,model.rand_d_max)\n",
    "    remove_list=random.sample(range(model.number_of_nodes),int(d*model.number_of_nodes))\n",
    "    # Remove randomly d*model.number_of_nodes nodes \n",
    "\n",
    "    return remove_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worst Removal \n",
    "The idea of worst removal is to remove the worst parts of the solution, i.e. those that cause the biggest costs, hoping that the repair\n",
    "heuristic is able to eliminate the huge costs. <br>\n",
    "Our mission is calculating the difference of the costs of the solution and the costs of the solution without that part.<br>\n",
    "The worst removal is more or less the same as random removal, but the difference is that the list is sorted in ascending order.<br>\n",
    "<br>\n",
    "After calculating all the differences, we can take a sets of $d$ elements (which have the biggest cost) to destroy and repair heuristic.<br> \n",
    "Note: $d$ acctually can be constant but ultilize the process, we can choose it randomly in the range of degree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createWorstDestory(model,sol):\n",
    "\n",
    "    diff=[]\n",
    "    for node_no in sol.nodes_sequence:\n",
    "        nodes_sequence=copy.deepcopy(sol.nodes_sequence)\n",
    "        nodes_sequence.remove(node_no)\n",
    "        obj,vehicle_routes=calObj(nodes_sequence,model)\n",
    "        # Take difference if remove node_no in nodes_sequence\n",
    "        diff.append(sol.obj - obj)\n",
    "\n",
    "    sorted_id = sorted(range(len(diff)), key=lambda k: diff[k], reverse=True)\n",
    "    #Select a random degree of destruction from [dmin,dmax] in every iteration.\n",
    "    d=random.randint(model.worst_d_min,model.worst_d_max)\n",
    "    # Take first d index of largest differences in nodes_sequence\n",
    "    remove_list=sorted_id[:d]\n",
    "    \n",
    "    return remove_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largestdistance(model):\n",
    "    return np.max(model.distance)\n",
    "\n",
    "def largestrequest(model):\n",
    "    max = -9999999999999999\n",
    "    for i in range(model.number_of_nodes):\n",
    "        if model.node_list[i].request>max:\n",
    "            max=model.node_list[i].request\n",
    "    return max\n",
    "\n",
    "# Largest distance between two points\n",
    "LarDis = largestdistance(model)\n",
    "LarReq = largestrequest(model)\n",
    "\n",
    "def createRelatedDestory(model, sol):\n",
    "    number_remove = min(model.number_of_nodes, random.randint(int(model.number_of_nodes*model.related_d_max), \n",
    "                                                int(model.number_of_nodes*model.related_d_min)))\n",
    "\n",
    "    nodes_sequence=copy.deepcopy(sol.nodes_sequence)\n",
    "    random_no = random.uniform(0, len(sol.nodes_sequence))\n",
    "    remove_list = []\n",
    "    remove_list.append(random_no)\n",
    "    nodes_sequence.remove(nodes_sequence[random_no])\n",
    "    number_remove -= 1\n",
    "    remove_no = 0\n",
    "\n",
    "    while number_remove > 0:\n",
    "        random_no = random.uniform(0, len(nodes_sequence))\n",
    "        argmin = 9999999999999999\n",
    "        for node_no in nodes_sequence:\n",
    "            if node_no!=random_no:\n",
    "                RelVal = model.varphi*model.distance[random_no, node_no]/LarDis + \\\n",
    "                        model.psi*(abs(model.node_list[random_no] - model.node_list[node_no]))/LarReq\n",
    "                if argmin<RelVal: \n",
    "                    remove_no=node_no\n",
    "                    argmin=RelVal\n",
    "            else:\n",
    "                continue\n",
    "            remove_list.append(remove_no)\n",
    "            nodes_sequence.remove(node_no)\n",
    "        number_remove -= 1\n",
    "        # Take difference if remove node_no in nodes_sequence\n",
    "    return remove_list\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repair Operators\n",
    "### Random Rapair\n",
    "Random repair is just for getting repair id if its value is 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRandomRepair(remove_list,model,sol):\n",
    "    unassigned_nodes_seq =[]\n",
    "    assigned_nodes_seq = []\n",
    "    # remove node from current solution\n",
    "    for i in range(model.number_of_nodes):\n",
    "        if i in remove_list:\n",
    "            unassigned_nodes_seq.append(sol.nodes_sequence[i])\n",
    "        else:\n",
    "            assigned_nodes_seq.append(sol.nodes_sequence[i])\n",
    "    # insert\n",
    "    for node_no in unassigned_nodes_seq:\n",
    "        index=random.randint(0,len(assigned_nodes_seq)-1)\n",
    "        assigned_nodes_seq.insert(index,node_no)\n",
    "    new_sol=Sol()\n",
    "    new_sol.nodes_sequence = copy.deepcopy(assigned_nodes_seq)\n",
    "    new_sol.obj,new_sol.routes = calObj(assigned_nodes_seq,model)\n",
    "    return new_sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy Repair heuristic\n",
    "Basic Greedy Repair determines the cheapest insertion position for all currently unserved requests.<br>\n",
    "First step is find the position to add element to assigned list from remove list. <br>\n",
    "The rule is simple: Add the smallest different cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findGreedyInsert(unassigned_nodes_seq,assigned_nodes_seq,model):\n",
    "    best_insert_node_no = None\n",
    "    best_insert_index = None\n",
    "    best_insert_cost = float(9999999999999999999999999)\n",
    "    # We only need to take assigned_nodes_seq_obj\n",
    "    assigned_nodes_seq_obj, _ = calObj(assigned_nodes_seq,model)\n",
    "    for node_no in unassigned_nodes_seq:\n",
    "        for i in range(len(assigned_nodes_seq)):\n",
    "            new_assigned_nodes_seq = copy.deepcopy(assigned_nodes_seq)\n",
    "            new_assigned_nodes_seq.insert(i, node_no)\n",
    "            obj, _ = calObj(new_assigned_nodes_seq, model)\n",
    "            diff = obj - assigned_nodes_seq_obj\n",
    "            if diff<best_insert_cost:\n",
    "                best_insert_index = i\n",
    "                best_insert_node_no = node_no\n",
    "                best_insert_cost = diff\n",
    "    return best_insert_node_no,best_insert_index\n",
    "\n",
    "\n",
    "def createGreedyRepair(remove_list,model,sol):\n",
    "    unassigned_nodes_seq = []\n",
    "    assigned_nodes_seq = []\n",
    "    # remove node from current solution\n",
    "    for i in range(model.number_of_nodes):\n",
    "        if i in remove_list:\n",
    "            unassigned_nodes_seq.append(sol.nodes_sequence[i])\n",
    "        else:\n",
    "            assigned_nodes_seq.append(sol.nodes_sequence[i])\n",
    "    #insert\n",
    "    while len(unassigned_nodes_seq)>0:\n",
    "        insert_node_no,insert_index = findGreedyInsert(unassigned_nodes_seq,assigned_nodes_seq,model)\n",
    "        assigned_nodes_seq.insert(insert_index,insert_node_no)\n",
    "        unassigned_nodes_seq.remove(insert_node_no)\n",
    "\n",
    "    new_sol=Sol()\n",
    "    new_sol.nodes_sequence=copy.deepcopy(assigned_nodes_seq)\n",
    "    new_sol.obj,new_sol.routes=calObj(assigned_nodes_seq,model)\n",
    "    return new_sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regret Repair\n",
    "Regret Repair takes an approach that is similar to Basic Greedy Repair. But instead of inserting the requests at the cheapest position, a Regret-n heuristic calculates a regret value based on $s_i(r)$, a modification of the current solution s, in which request r has been inserted in the i-cheapest tour. <br><br>\n",
    "In general, a Regret-n heuristic calculates the part with the greatest cost difference between the cheapest and the n - 1 next cheapest insertions. The next insertion candidate can be determined by\n",
    "$$\\argmax_{r \\in R^-} \\biggl\\{\\sum_{i=1}^{n}(c(s_i(r)) - c(s_1(r))) \\biggl\\}  (*)$$\n",
    "Here, R- stands for the set of currently unassigned requests (*unassigned_nodes_seq*)\n",
    "#### Repair Heuristic Parameters\n",
    "About param value, there can possibly be an arbitrary number of Regret Repair heuristics (Regret_n) .<br><br>\n",
    "![image info](./datatest/regret.png) <br><br>\n",
    "The noise , i.e a random number from an interval whose length is influenced by $\\eta$, is added to the cost increase values in the\n",
    "repair heuristics. In the special case Î· = 0, no noise is used at all. The three best configurations had a $\\eta$ value\n",
    "of 0.4238, 0.4268 and 0.4700 (As the book said)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRegretInsert(unassigned_nodes_seq,assigned_nodes_seq,model):\n",
    "    opt_insert_node_no = None\n",
    "    opt_insert_index = None\n",
    "    opt_insert_cost = -float(9999999999999999999999999)\n",
    "    for node_no in unassigned_nodes_seq:\n",
    "        # Create a matrix size 3 x len(assigned_nodes_seq)\n",
    "        n_insert_cost = np.zeros((len(assigned_nodes_seq),3))\n",
    "        for i in range(len(assigned_nodes_seq)):\n",
    "            new_assigned_nodes_seq = copy.deepcopy(assigned_nodes_seq)\n",
    "            new_assigned_nodes_seq.insert(i,node_no)\n",
    "            obj, _ = calObj(new_assigned_nodes_seq,model)\n",
    "            n_insert_cost[i,0]=node_no\n",
    "            n_insert_cost[i,1]=i\n",
    "            n_insert_cost[i,2]=obj\n",
    "            \n",
    "        n_insert_cost= n_insert_cost[n_insert_cost[:, 2].argsort()]\n",
    "        \n",
    "        diff=0\n",
    "        for i in range(1,model.regret_n):\n",
    "            diff +=  n_insert_cost[i,2] - n_insert_cost[0,2]\n",
    "        # Here the (*) :\n",
    "        if diff>opt_insert_cost:\n",
    "            opt_insert_node_no = int(n_insert_cost[0, 0])\n",
    "            opt_insert_index = int(n_insert_cost[0,1])\n",
    "            opt_insert_cost = diff\n",
    "    return opt_insert_node_no,opt_insert_index\n",
    "\n",
    "\n",
    "def createRegretRepair(remove_list,model,sol):\n",
    "    unassigned_nodes_seq = []\n",
    "    assigned_nodes_seq = []\n",
    "    # remove node from current solution\n",
    "    for i in range(model.number_of_nodes):\n",
    "        if i in remove_list:\n",
    "            unassigned_nodes_seq.append(sol.nodes_sequence[i])\n",
    "        else:\n",
    "            assigned_nodes_seq.append(sol.nodes_sequence[i])\n",
    "    # insert\n",
    "    while len(unassigned_nodes_seq)>0:\n",
    "        insert_node_no,insert_index=findRegretInsert(unassigned_nodes_seq,assigned_nodes_seq,model)\n",
    "        assigned_nodes_seq.insert(insert_index,insert_node_no)\n",
    "        unassigned_nodes_seq.remove(insert_node_no)\n",
    "        \n",
    "    new_sol = Sol()\n",
    "    new_sol.nodes_sequence = copy.deepcopy(assigned_nodes_seq)\n",
    "    new_sol.obj, new_sol.routes = calObj(assigned_nodes_seq, model)\n",
    "    return new_sol\n",
    "# sol = Sol()\n",
    "# sol.nodes_sequence = genInitialSol(model.node_seq_no_list)\n",
    "# remove_list = createRandomDestory(model)\n",
    "# createRegretRepair(remove_list,model,sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Destroy and Repair to do\n",
    "Repair and destroy heuristic in each iteration are chosen from sets of heuristics due to the probability depended on weights (The probability equation is shown below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doDestory(destory_id,model,sol):\n",
    "    if destory_id==0:\n",
    "        remove_list=createRandomDestory(model)\n",
    "    else:\n",
    "        remove_list=createWorstDestory(model,sol)\n",
    "    return remove_list\n",
    "\n",
    "def doRepair(repair_id,remove_list,model,sol):\n",
    "    if repair_id==0:\n",
    "        new_sol=createRandomRepair(remove_list,model,sol)\n",
    "    elif repair_id==1:\n",
    "        new_sol=createGreedyRepair(remove_list,model,sol)\n",
    "    else:\n",
    "        new_sol=createRegretRepair(remove_list,model,sol)\n",
    "    return new_sol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Scheme\n",
    "Actually, the weight reflects heuristic's success.<br>\n",
    "The selection of a heuristic in each iteration is then based on these weights.<br>\\\n",
    "Let $D = \\{d_i|i = 1,...,k\\}$ be the set of k destroy heuristics and\n",
    "$S = \\{r_i|i = 1,...,l\\}$ be the set of l repair heuristics. The initially equal weights\n",
    "of the heuristics are denoted by $w(r_i)$ and $w(d_i)$ <br>\n",
    "The probabilities to select a heuristic: \n",
    "$$p(r_i)=\\frac{w(r_i)}{\\sum_{j=1}^{k} w(r_i)}, p(d_i)=\\frac{w(d_i)}{\\sum_{j=1}^{l} w(d_i)}$$\n",
    "(That is cumulative sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectDestoryRepair(model):\n",
    "    d_weight=model.d_weight\n",
    "    d_prob = np.cumsum(d_weight / sum(d_weight))\n",
    "    d_prob -= np.random.rand()\n",
    "    destory_id = None\n",
    "    for d_no in range(len(d_prob)):\n",
    "        if d_prob[d_no] > 0: \n",
    "            destory_id = d_no\n",
    "            break\n",
    "\n",
    "    r_weight=model.r_weight\n",
    "    r_prob = np.cumsum(r_weight / sum(r_weight))\n",
    "    r_prob -= np.random.rand()\n",
    "    repair_id = None\n",
    "    for r_no in range(len(r_prob)):\n",
    "        if r_prob[r_no] > 0: \n",
    "            repair_id = r_no\n",
    "            break\n",
    "\n",
    "    return destory_id,repair_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights Updating\n",
    "Adjusting the weights of the heuristics is necessary in order to increase the probability that successful heuristics are used more often than less successful heuristics for a specific problem instance. The dynamic adjustments are the only way to ensure permanent re-evalution of the heuristics.<br>\n",
    "We need to determine the weight adjustment $w(h)$ ($w(h)$ denotes the weight of a heuristic $h$).\n",
    "We calculate the weights for the following iterations by\n",
    "$$M = \\biggl\\{\\begin{array}{cc} \n",
    "(1-\\rho)w(h) + \\rho \\frac{s(h)}{u(h)}, & \\text{if u(h) > 0}\\\\\n",
    "(1-\\rho)w(h) , & \\text{if u(h) = 0}\n",
    "\\end{array}$$\n",
    "The weights of destroy and repair heuristic is calculated independently. <br>\n",
    "Note: \n",
    "- $s(h)$ stands for the success of solution. In here, we define it as score.\n",
    "- $u(h)$ is the number of times the heuristic $h$ has been used during the $p_u$ iterations.\n",
    "- The reaction factor $\\rho$ controls the influence of the recent success of a heuristic on its weight. <br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetScore(model):\n",
    "\n",
    "    model.d_select = np.zeros(2)\n",
    "    model.d_score = np.zeros(2)\n",
    "\n",
    "    model.r_select = np.zeros(3)\n",
    "    model.r_score = np.zeros(3)\n",
    "\n",
    "# Reaction factor rho\n",
    "def updateWeight(model):\n",
    "    for i in range(model.d_weight.shape[0]):\n",
    "        if model.d_select[i]>0:\n",
    "            model.d_weight[i] = model.d_weight[i]*(1-model.rho) + (model.rho*model.d_score[i]/model.d_select[i])\n",
    "        else:\n",
    "            model.d_weight[i] = model.d_weight[i] * (1 - model.rho)\n",
    "    for i in range(model.r_weight.shape[0]):\n",
    "        if model.r_select[i]>0:\n",
    "            model.r_weight[i] = model.r_weight[i]*(1-model.rho) + (model.rho*model.r_score[i]/model.r_select[i])\n",
    "        else:\n",
    "            model.r_weight[i] = model.r_weight[i] * (1 - model.rho)\n",
    "            \n",
    "    model.d_history_select = model.d_history_select + model.d_select\n",
    "    model.d_history_score = model.d_history_score + model.d_score\n",
    "    model.r_history_select = model.r_history_select + model.r_select\n",
    "    model.r_history_score = model.r_history_score + model.r_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotObj(obj_list):\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.plot(np.arange(1,len(obj_list)+1),obj_list)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Obj Value')\n",
    "    plt.grid()\n",
    "    plt.xlim(1,len(obj_list)+1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(filepath,rand_d_max,rand_d_min,worst_d_min,worst_d_max,related_d_min,related_d_max,varphi,psi,regret_n,r1,r2,r3,rho,phi,epochs,freq_WA,vehicle_cap,opt_type):\n",
    "    \n",
    "    model=Model()\n",
    "    model.rand_d_max=rand_d_max\n",
    "    model.rand_d_min=rand_d_min\n",
    "    model.worst_d_min=worst_d_min\n",
    "    model.worst_d_max=worst_d_max\n",
    "    model.related_d_min=related_d_min\n",
    "    model.related_d_max=related_d_max\n",
    "    model.regret_n=regret_n\n",
    "    model.r1=r1\n",
    "    model.r2=r2\n",
    "    model.r3=r3\n",
    "    model.rho=rho\n",
    "    model.varphi=varphi\n",
    "    model.psi=psi\n",
    "    model.vehicle_cap=vehicle_cap\n",
    "    model.opt_type=opt_type\n",
    "    ##\n",
    "    readDataFile(filepath, model)\n",
    "    initParam(model)\n",
    "    ##\n",
    "    history_best_obj = []\n",
    "    sol = Sol()\n",
    "    sol.nodes_sequence = genInitialSol(model.node_seq_no_list)\n",
    "    sol.obj, sol.routes = calObj(sol.nodes_sequence, model)\n",
    "    model.best_sol = copy.deepcopy(sol)\n",
    "    history_best_obj.append(sol.obj)\n",
    "    for ep in range(epochs):\n",
    "        # Parameter tolerance:  tol can be chosen in range of [0, 0.3]. \n",
    "        tol = 0.2\n",
    "        T = sol.obj*tol\n",
    "        resetScore(model)\n",
    "        for k in range(freq_WA):\n",
    "            destory_id,repair_id = selectDestoryRepair(model)\n",
    "            model.d_select[destory_id] += 1\n",
    "            model.r_select[repair_id] += 1\n",
    "            remove_list = doDestory(destory_id,model,sol)\n",
    "            new_sol = doRepair(repair_id,remove_list,model,sol)\n",
    "            if new_sol.obj < sol.obj:\n",
    "                sol = copy.deepcopy(new_sol)\n",
    "                if new_sol.obj<model.best_sol.obj:\n",
    "                    model.best_sol = copy.deepcopy(new_sol)\n",
    "                    model.d_score[destory_id] += model.r1\n",
    "                    model.r_score[repair_id] += model.r1\n",
    "                else:\n",
    "                    model.d_score[destory_id] += model.r2\n",
    "                    model.r_score[repair_id] += model.r2\n",
    "            elif new_sol.obj-sol.obj < T:\n",
    "                sol=copy.deepcopy(new_sol)\n",
    "                model.d_score[destory_id] += model.r3\n",
    "                model.r_score[repair_id] += model.r3\n",
    "            # The threshold is decreased in every iteration by a factor phi  \n",
    "            T=T*phi\n",
    "            print(\"%s/%s:%s/%s,  best heuristic objective: %s\" % (ep,epochs,k,freq_WA, model.best_sol.obj))\n",
    "            history_best_obj.append(model.best_sol.obj)\n",
    "        updateWeight(model)\n",
    "        \n",
    "    plotObj(history_best_obj)\n",
    "\n",
    "    print(\"random removal weight is {:.3f}\\tselect is {}\\tscore is {:.3f}\".format(model.d_weight[0],\n",
    "                                                                        model.d_history_select[0],\n",
    "                                                                        model.d_history_score[0]))\n",
    "    print(\"worst removal weight is {:.3f}\\tselect is {}\\tscore is {:.3f} \".format(model.d_weight[1],\n",
    "                                                                        model.d_history_select[1],\n",
    "                                                                        model.d_history_score[1]))\n",
    "    print(\"random repair weight is {:.3f}\\tselect is {}\\tscore is {:.3f}\".format(model.r_weight[0],\n",
    "                                                                       model.r_history_select[0],\n",
    "                                                                       model.r_history_score[0]))\n",
    "    print(\"greedy repair weight is {:.3f}\\tselect is {}\\tscore is {:.3f}\".format(model.r_weight[1],\n",
    "                                                                       model.r_history_select[1],\n",
    "                                                                       model.r_history_score[1]))\n",
    "    print(\"regret repair weight is {:.3f}\\tselect is {}\\tscore is {:.3f}\".format(model.r_weight[2],\n",
    "                                                                       model.r_history_select[2],\n",
    "                                                                       model.r_history_score[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/32:0/5,  best heuristic objective: 5153.510090364812\n",
      "0/32:1/5,  best heuristic objective: 3785.1316249870024\n",
      "0/32:2/5,  best heuristic objective: 3336.4022477455947\n",
      "0/32:3/5,  best heuristic objective: 3057.17877396456\n",
      "0/32:4/5,  best heuristic objective: 3057.17877396456\n",
      "1/32:0/5,  best heuristic objective: 3057.17877396456\n",
      "1/32:1/5,  best heuristic objective: 3057.17877396456\n",
      "1/32:2/5,  best heuristic objective: 3057.17877396456\n",
      "1/32:3/5,  best heuristic objective: 3057.17877396456\n",
      "1/32:4/5,  best heuristic objective: 3057.17877396456\n",
      "2/32:0/5,  best heuristic objective: 2780.6161065786587\n"
     ]
    }
   ],
   "source": [
    "Filee = '../CVRP_ALNS/datatest/ALNS_CVRP.txt'\n",
    "rand_d_max=0.4\n",
    "rand_d_min=0.1\n",
    "worst_d_min=5\n",
    "worst_d_max=20\n",
    "regret_n=5\n",
    "\n",
    "related_d_min = 0.1\n",
    "related_d_max = 0.4\n",
    "\n",
    "varphi = 2\n",
    "psi = 1\n",
    "\n",
    "#Score\n",
    "r1=30\n",
    "r2=20\n",
    "r3=10\n",
    "# Reaction factor of action weight\n",
    "rho=0.4\n",
    "# Reduction factor of threshold acceptance\n",
    "phi=0.9997\n",
    "# Set number of epochs\n",
    "epochs=32\n",
    "# Frequency of Weight Adjustment\n",
    "freq_WA=5\n",
    "vehicle_cap=80\n",
    "# Optimization type\n",
    "opt_type=1\n",
    "\n",
    "\n",
    "\n",
    "run(Filee, rand_d_max, rand_d_min, worst_d_min, worst_d_max,related_d_min, related_d_max , regret_n, r1, r2, r3, rho,\n",
    "    phi, varphi , psi , epochs, freq_WA, vehicle_cap, opt_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31671a60cee805c34c73116577b485118ff3a75c458d3004d49632c19702ac60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
